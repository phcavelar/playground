{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Variational Autoencoders and Exploring Autoencoder Latent Spaces\n",
    "\n",
    "This is a small notebook and experiment to show how to use conditional generation and optimise the latent space w.r.t. some sort of feature.\n",
    "\n",
    "This is partly based on the blogpost [Conditional generation via Bayesian optimization in latent space by Martin Krasser](https://krasserm.github.io/2018/04/07/latent-space-optimization/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment\n",
    "\n",
    "We use [miniconda](https://docs.conda.io/en/latest/miniconda.html) (and we recommend also having [mamba](https://mamba.readthedocs.io/en/latest/installation.html#installation)) to setup the environment and we have only tested this way. If you want to install the packages through pip you are on your own.\n",
    "\n",
    "We provide a simple setup script that checks your system for GPU and CUDA versions using `nvidia-smi`, (re-)creates the environment using `conda`, and installs the packages according to your system using either `mamba` or `conda`. To use this script to setup your environment, you only need to run:\n",
    "```sh\n",
    "chmod a+x cond_vae_setup.sh\n",
    "./cond_vae_setup.sh\n",
    "```\n",
    "\n",
    "Note that we only tested our environment on a NVIDIA RTX A4000 on Ubuntu 22.04.02, with driver version 515.105.01, NVIDIA-SMI 515.105.01, and CUDA Version 11.7. If you find any problems with other setups feel free to raise an issue.\n",
    "\n",
    "All our `.yml` files contain major and minor versions for libraries, with debug versions of some of the libraries. If you can't find a combination for your system, try [relaxing the versions](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#create-env-file-manually). However, it might be possible that this notebook won't work with some of the relaxed versions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folders and settings\n",
    "\n",
    "The strings below define where we will search for and store data, results, images, and models. Please change it if you want to use other folders than the default ones. Some of the libraries we use might have library-specific defaults which can be shared among environments, and we keep those separate.\n",
    "\n",
    "Also, we have some variables that define behavious along the script, for example defining which images extensions to save, whether to show images in the notebook, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders to use\n",
    "data_folder = \"~/data\"\n",
    "results_folder = \"./cond_vae/results\"\n",
    "models_folder = \"./cond_vae/models\"\n",
    "images_folder = \"./cond_vae/images\"\n",
    "\n",
    "# Which dataset to use MNIST/FASHION MNIST\n",
    "DATASET_TO_USE = \"MNIST\"\n",
    "\n",
    "# Autoencoder training hyperparameters\n",
    "N_EPOCHS = 16\n",
    "BATCH_SIZE = 64\n",
    "AE_LATENT_DIM = 2\n",
    "assert AE_LATENT_DIM==2, NotImplementedError(\"The notebook has not been adapted to dimensions other than 2 yet\")\n",
    "\n",
    "# External classifier (For bayesian exploration) training hyperparameters\n",
    "CLF_N_EPOCHS = 16\n",
    "CLF_BATCH_SIZE = 64\n",
    "BAYESIAN_OPTIMISATION_STEPS = 64\n",
    "\n",
    "# Point-grid and KDE generative exploration hyperparameters\n",
    "NUM_POINTS_GRID = 128\n",
    "NUMBER_OF_SAMPLES_PER_CLASS = 4\n",
    "TOP_PCT_TO_SAMPLE_FROM = 0.01\n",
    "SOFTMAX_REPARAM_TEMPERATURE = 1\n",
    "\n",
    "# Image variables\n",
    "YLABEL_FONTSIZE = 6\n",
    "COORDS_FONTSIZE = 8\n",
    "SHOW_IMAGES = True\n",
    "SAVE_IMAGES = True\n",
    "# I do not recommend saving vectorial images, as they become quite large with the amount of points being plotted.\n",
    "IMAGE_FORMATS = [\"jpg\", \"png\"]\n",
    "SHOW_ACQUISITIONS = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the folders we might be using for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "data_folder, results_folder, models_folder, images_folder = map(\n",
    "    osp.expanduser,\n",
    "    map(\n",
    "        osp.expandvars,\n",
    "        (data_folder, results_folder, models_folder, images_folder)\n",
    "    )\n",
    ")\n",
    "\n",
    "for f in [data_folder, results_folder, models_folder]:\n",
    "    os.makedirs(f, exist_ok=True)\n",
    "\n",
    "for fmt in IMAGE_FORMATS:\n",
    "    os.makedirs(osp.join(images_folder,fmt), exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import interleave, take\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch numpy bool back for GPyOpt\n",
    "np.bool = bool\n",
    "import GPyOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST, FashionMNIST, KMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from medmnist import OrganAMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match DATASET_TO_USE.lower():\n",
    "    case \"mnist\":\n",
    "        mnist_train = MNIST(root=data_folder, download=True, train=True, transform=ToTensor(),)\n",
    "        mnist_test = MNIST(root=data_folder, download=True, train=False, transform=ToTensor(),)\n",
    "        mnist_n_channels = 1\n",
    "    case \"kmnist\":\n",
    "        mnist_train = KMNIST(root=data_folder, download=True, train=True, transform=ToTensor(),)\n",
    "        mnist_test = KMNIST(root=data_folder, download=True, train=False, transform=ToTensor(),)\n",
    "        mnist_n_channels = 1\n",
    "    case \"fashionmnist\":\n",
    "        mnist_train = FashionMNIST(root=data_folder, download=True, train=True, transform=ToTensor(),)\n",
    "        mnist_test = FashionMNIST(root=data_folder, download=True, train=True, transform=ToTensor(),)\n",
    "        mnist_n_channels = 1\n",
    "    case \"organamnist\":\n",
    "        mnist_train = OrganAMNIST(root=data_folder, download=True, split=\"train\", transform=ToTensor(),)\n",
    "        mnist_test = OrganAMNIST(root=data_folder, download=True, split=\"val\", transform=ToTensor(),)\n",
    "        for dset in [mnist_train,mnist_test]:\n",
    "            dset.data = dset.imgs\n",
    "            dset.labels = dset.labels.squeeze()\n",
    "            dset.targets = torch.tensor(dset.labels)\n",
    "            dset.classes = [dset.info[\"label\"][str(i)] for i in range(len(dset.info[\"label\"]))]\n",
    "        mnist_n_channels = 1\n",
    "    case _:\n",
    "        raise ValueError(f\"Specified dataset {DATASET_TO_USE} is not available\")\n",
    "    \n",
    "tuple(map(lambda x: (x.data.shape, x.targets.shape), (mnist_train, mnist_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = next(iter(mnist_train))[0].shape\n",
    "assert data_shape[1] == data_shape[2], NotImplementedError(f\"You tried plugging in a dataset that has non-square images (shape {data_shape}), which will break the code.\")\n",
    "dset_img_dim = data_shape[1]\n",
    "assert (dset_img_dim%2==0 and dset_img_dim%4==0), NotImplementedError(f\"Dataset dimensionality {dset_img_dim} must be divisible by 4\")\n",
    "dset_img_dim_half = dset_img_dim//2\n",
    "dset_img_dim_fourth = dset_img_dim//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.asarray(mnist_train.classes)\n",
    "mnist_n_classes = len(class_names)\n",
    "class_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimisation Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_optimizer_for(\n",
    "                target:int,\n",
    "                decoder:nn.Module,\n",
    "                classifier:nn.Module,\n",
    "                bounds:list[tuple[float,float]],\n",
    "                normal_means:list[float]|np.ndarray = [0],\n",
    "                normal_covs:str|list[list[float]]|np.ndarray = \"eye\",\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Returns a GPyOpt bayesian optimiser that searches inside our latent space for values which,\n",
    "    after being reconstructed by our decoder, are correctly classified by our optimiser. \n",
    "    \"\"\"\n",
    "    \n",
    "    bounds = [\n",
    "        {\"name\": f\"t{i+1}\", \"type\": \"continuous\", \"domain\": (i_min, i_max)}\n",
    "        for i, (i_min, i_max) in enumerate(bounds)\n",
    "    ]\n",
    "\n",
    "    if isinstance(normal_means, list) and len(normal_means)==1:\n",
    "        normal_means = normal_means * len(bounds)\n",
    "    else:\n",
    "        try:\n",
    "            normal_means = np.asarray(normal_means)\n",
    "        except (ValueError, NotImplementedError) as e:\n",
    "            raise ValueError(f\"Could not convert normal_means of type {type(normal_means)} to a numpy array. Original Exception: {e}\")\n",
    "        if len(normal_means.shape)==0 or (np.prod(normal_means.shape)==1):\n",
    "            normal_means = [normal_means.item()]\n",
    "        elif np.prod(normal_means.shape)==len(bounds):\n",
    "            normal_means = normal_means.squeeze()\n",
    "        else:\n",
    "            raise ValueError(f\"normal_means array has shape {normal_means.shape} which is incompatible with the provided number of bounds {len(bounds)}\")\n",
    "\n",
    "    if isinstance(normal_covs, str):\n",
    "        match normal_covs:\n",
    "            case \"eye\":\n",
    "                normal_covs = np.eye(len(bounds))\n",
    "            case _:\n",
    "                raise ValueError(f\"normal_covs string method {normal_covs} unrecognised. See the function definition for available types\")\n",
    "    elif isinstance(normal_covs, list):\n",
    "        if len(normal_covs)==len(bounds):\n",
    "            for i, row in enumerate(normal_covs):\n",
    "                assert isinstance(row,list), ValueError(f\"normal_covs must be 2 dimensional, but its {i}th value was not a list.\")\n",
    "                assert len(row)==len(bounds), ValueError(f\"normal_covs must be 2 dimensional, but its {i}th value had length {len(row)} instead of {len(bounds)}.\")\n",
    "        else:\n",
    "            raise ValueError(f\"normal_covs has incompatible length {len(normal_covs)} with the bounds {len(bounds)}\")\n",
    "    else:\n",
    "        try:\n",
    "            normal_covs = np.asarray(normal_covs)\n",
    "        except (ValueError, NotImplementedError) as e:\n",
    "            raise ValueError(f\"Could not convert normal_means of type {type(normal_covs)} to a numpy array. Original Exception: {e}\")\n",
    "        assert (len(normal_covs.shape) == 2 and all((s == len(bounds) for s in normal_covs.shape))), ValueError(f\"normal_covs must a {len(bounds)}×{len(bounds)} matrix, but its shape was {normal_covs.shape}.\")\n",
    "        \n",
    "    mvn = sps.multivariate_normal(mean=normal_means, cov=normal_covs)\n",
    "    found_device = next(decoder.parameters()).device\n",
    "    found_dtype = next(decoder.parameters()).dtype\n",
    "\n",
    "    # Create a negative_log_likelihood function for our target as a closure\n",
    "    def negative_log_likelihood(t):\n",
    "        \"\"\"\n",
    "        Our Bayesian optimisation objective which is a negative likelihood function that\n",
    "        uses our decoder to decode the latent space being explored and then uses our\n",
    "        classifier to classify it.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Decode latent vector into image\n",
    "            decoded = decoder(torch.tensor(t, device=found_device, dtype=found_dtype))\n",
    "            # Predict probabilities with separate classifier\n",
    "            c_probs = torch.softmax(classifier(decoded), 1).detach().cpu().numpy()\n",
    "\n",
    "        nll_prior = -mvn.logpdf(t).reshape(-1, 1)\n",
    "        # Get the negative log likelihood for our predicted probability (plus an epsilon for stability)\n",
    "        nll_pred = -np.log(c_probs[:,target] + 1e-8).reshape(-1, 1)\n",
    "        \n",
    "        return nll_prior + nll_pred\n",
    "\n",
    "    return GPyOpt.methods.BayesianOptimization(f=negative_log_likelihood, \n",
    "                                domain=bounds,\n",
    "                                model_type='GP',\n",
    "                                acquisition_type ='EI',\n",
    "                                acquisition_jitter = 0.01,\n",
    "                                initial_design_numdata = 2,\n",
    "                                exact_feval=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Conv2dKeras(torch.nn.Conv2d):\n",
    "    \"\"\"\n",
    "    Conv2d with keras behaviour for padding=\"same\"\n",
    "    From: https://stackoverflow.com/a/73332370\n",
    "    \"\"\"\n",
    "    def calc_same_pad(self, i: int, k: int, s: int, d: int) -> int:\n",
    "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ih, iw = x.size()[-2:]\n",
    "\n",
    "        pad_h = self.calc_same_pad(i=ih, k=self.kernel_size[0], s=self.stride[0], d=self.dilation[0])\n",
    "        pad_w = self.calc_same_pad(i=iw, k=self.kernel_size[1], s=self.stride[1], d=self.dilation[1])\n",
    "\n",
    "        print(x.shape)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(\n",
    "                x,\n",
    "                [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2],\n",
    "                mode=(\"constant\" if self.padding_mode == \"zeros\" else self.padding_mode),\n",
    "            )\n",
    "        print(x.shape)\n",
    "        return F.conv2d(\n",
    "            x,\n",
    "            self.weight,\n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            dilation=self.dilation,\n",
    "            groups=self.groups,\n",
    "        )\n",
    "\n",
    "import math\n",
    "\n",
    "class ConvTranspose2dKeras(torch.nn.Conv2d):\n",
    "    \"\"\"\n",
    "    ConvTranspose2d with keras behaviour for padding=\"same\"\n",
    "    From: https://stackoverflow.com/a/73332370\n",
    "    \"\"\"\n",
    "    def calc_same_pad(self, i: int, k: int, s: int, d: int) -> int:\n",
    "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ih, iw = x.size()[-2:]\n",
    "\n",
    "        pad_h = self.calc_same_pad(i=ih, k=self.kernel_size[0], s=self.stride[0], d=self.dilation[0])\n",
    "        pad_w = self.calc_same_pad(i=iw, k=self.kernel_size[1], s=self.stride[1], d=self.dilation[1])\n",
    "\n",
    "        print(x.shape)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(\n",
    "                x,\n",
    "                [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2],\n",
    "                mode=(\"constant\" if self.padding_mode == \"zeros\" else self.padding_mode),\n",
    "            )\n",
    "        print(x.shape)\n",
    "        return F.conv_transpose2d(\n",
    "            x,\n",
    "            self.weight,\n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            dilation=self.dilation,\n",
    "            groups=self.groups,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NopLayer(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super(NopLayer,self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features:int,\n",
    "                 features_defs:list[int],\n",
    "                 nonlinearities:list[nn.Module] = [nn.ReLU],\n",
    "                 drop_last_nonlinearity = False,\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        TODO: Describe\n",
    "        \"\"\"\n",
    "        super(MLP,self).__init__()\n",
    "        n_layers = len(features_defs)\n",
    "        in_features_defs = [in_features] + features_defs[:-1]\n",
    "        out_features_defs = features_defs\n",
    "        if len(nonlinearities) == 1: nonlinearities = nonlinearities*n_layers\n",
    "\n",
    "        assert all(map(lambda l: len(l)==n_layers, [in_features_defs, out_features_defs, nonlinearities]))\n",
    "\n",
    "        if len(nonlinearities)==n_layers and drop_last_nonlinearity:\n",
    "            nonlinearities[-1] = NopLayer\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            *interleave(\n",
    "                (\n",
    "                    nn.Linear(\n",
    "                        in_features=d_i,\n",
    "                        out_features=d_o,\n",
    "                    ) for d_i, d_o in zip(\n",
    "                        in_features_defs,\n",
    "                        out_features_defs,\n",
    "                    )\n",
    "                ),\n",
    "                [Nl() for Nl in nonlinearities],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels:int,\n",
    "                 channel_defs:list[int],\n",
    "                 kernel_defs:list[int|tuple[int]],\n",
    "                 stride_defs:list[int|tuple[int]] = [1],\n",
    "                 padding_defs:list[str|int|tuple[int]] = [\"same\"],\n",
    "                 padding_mode_defs:list[str] = [\"zeros\"],\n",
    "                 nonlinearities:list[nn.Module] = [nn.ReLU],\n",
    "                 post_nonlinearity_defs:list[nn.Module] = [NopLayer],\n",
    "                 post_nonlinearity_defs_args:list[list] = [[]],\n",
    "                 post_nonlinearity_defs_kwargs:list[dict] = [{}],\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        TODO: Describe\n",
    "        \"\"\"\n",
    "        super(CNN,self).__init__()\n",
    "        n_convs = len(channel_defs)\n",
    "        in_channel_defs = [in_channels] + channel_defs[:-1]\n",
    "        out_channel_defs = channel_defs\n",
    "        if len(kernel_defs) == 1: kernel_defs = kernel_defs*n_convs\n",
    "        if len(stride_defs) == 1: stride_defs = stride_defs*n_convs\n",
    "        if len(padding_defs) == 1: padding_defs = padding_defs*n_convs\n",
    "        if len(padding_mode_defs) == 1: padding_mode_defs = padding_mode_defs*n_convs\n",
    "        if len(nonlinearities) == 1: nonlinearities = nonlinearities*n_convs\n",
    "        if len(post_nonlinearity_defs) == 1: post_nonlinearity_defs = post_nonlinearity_defs*n_convs\n",
    "        if len(post_nonlinearity_defs_args) == 1: post_nonlinearity_defs_args = post_nonlinearity_defs_args*n_convs\n",
    "        if len(post_nonlinearity_defs_kwargs) == 1: post_nonlinearity_defs_kwargs = post_nonlinearity_defs_kwargs*n_convs\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            *interleave(\n",
    "                (\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=d_i,\n",
    "                        out_channels=d_o,\n",
    "                        kernel_size=k,\n",
    "                        stride=s,\n",
    "                        padding=p,\n",
    "                        padding_mode=pm\n",
    "                    ) for d_i, d_o, k, s, p, pm in zip(\n",
    "                        in_channel_defs,\n",
    "                        out_channel_defs,\n",
    "                        kernel_defs,\n",
    "                        stride_defs,\n",
    "                        padding_defs,\n",
    "                        padding_mode_defs,\n",
    "                    )\n",
    "                ),\n",
    "                [Nl() for Nl in nonlinearities],\n",
    "                [\n",
    "                    Layer(\n",
    "                        *layer_args,\n",
    "                        **layer_kwargs\n",
    "                    ) for Layer, layer_args, layer_kwargs in zip(\n",
    "                        post_nonlinearity_defs,\n",
    "                        post_nonlinearity_defs_args,\n",
    "                        post_nonlinearity_defs_kwargs,\n",
    "                    )   \n",
    "                ],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.cnn(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeCNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels:int,\n",
    "                 channel_defs:list[int],\n",
    "                 kernel_defs:list[int|tuple[int]],\n",
    "                 stride_defs:list[int|tuple[int]] = [1],\n",
    "                 padding_defs:list[str|int|tuple[int]] = [\"same\"],\n",
    "                 output_padding_defs:list[str|int|tuple[int]] = [0],\n",
    "                 padding_mode_defs:list[str] = [\"zeros\"],\n",
    "                 nonlinearities:list[nn.Module] = [nn.ReLU],\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        TODO: Describe\n",
    "        \"\"\"\n",
    "        super(DeCNN,self).__init__()\n",
    "        n_convs = len(channel_defs)\n",
    "        in_channel_defs = [in_channels] + channel_defs[:-1]\n",
    "        out_channel_defs = channel_defs\n",
    "        if len(kernel_defs) == 1: kernel_defs = kernel_defs*n_convs\n",
    "        if len(nonlinearities) == 1: nonlinearities = nonlinearities*n_convs\n",
    "        if len(stride_defs) == 1: stride_defs = stride_defs*n_convs\n",
    "        if len(padding_defs) == 1: padding_defs = padding_defs*n_convs\n",
    "        if len(padding_mode_defs) == 1: padding_mode_defs = padding_mode_defs*n_convs\n",
    "\n",
    "        self.decnn = nn.Sequential(\n",
    "            *interleave(\n",
    "                (\n",
    "                    nn.ConvTranspose2d(\n",
    "                        in_channels=d_i,\n",
    "                        out_channels=d_o,\n",
    "                        kernel_size=k,\n",
    "                        stride=s,\n",
    "                        padding=p,\n",
    "                        output_padding=op,\n",
    "                        padding_mode=pm\n",
    "                    ) for d_i, d_o, k, s, p, op, pm in zip(\n",
    "                        in_channel_defs,\n",
    "                        out_channel_defs,\n",
    "                        kernel_defs,\n",
    "                        stride_defs,\n",
    "                        padding_defs,\n",
    "                        output_padding_defs,\n",
    "                        padding_mode_defs,\n",
    "                    )\n",
    "                ),\n",
    "                [Nl() for Nl in nonlinearities],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.decnn(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_channels = 1, n_classes=10):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.clf = nn.Sequential(\n",
    "            CNN(\n",
    "                in_channels,\n",
    "                [32,64,64,],\n",
    "                [3,3,3,],\n",
    "                [1,1,1,],\n",
    "                [1,1,1,],\n",
    "                post_nonlinearity_defs=[\n",
    "                    nn.MaxPool2d,\n",
    "                    nn.MaxPool2d,\n",
    "                    nn.Flatten\n",
    "                ],\n",
    "                post_nonlinearity_defs_args=[\n",
    "                    [(2,2)],\n",
    "                    [(2,2)],\n",
    "                    [],\n",
    "                ]\n",
    "            ),\n",
    "            MLP(\n",
    "                64*dset_img_dim_fourth*dset_img_dim_fourth,\n",
    "                [64,mnist_n_classes],\n",
    "                drop_last_nonlinearity=True\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.clf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ext_clf\"\n",
    "\n",
    "ext_clf = Classifier(1)\n",
    "if torch.cuda.is_available():\n",
    "    ext_clf.cuda()\n",
    "\n",
    "ext_clf_opt = optim.Adam(ext_clf.parameters())\n",
    "\n",
    "xe_loss = nn.CrossEntropyLoss()\n",
    "total_loss = lambda xe_loss: xe_loss\n",
    "\n",
    "train_history = {\n",
    "    \"epoch\": [],\n",
    "    \"batch\": [],\n",
    "    \"clf_xe_loss\": [],\n",
    "    \"clf_acc\": [],\n",
    "    \"total_loss\": [],\n",
    "}\n",
    "test_history = {\n",
    "    \"epoch\": [],\n",
    "    \"batch\": [],\n",
    "    \"clf_xe_loss\": [],\n",
    "    \"clf_acc\": [],\n",
    "    \"total_loss\": [],\n",
    "}\n",
    "\n",
    "for e in tqdm(range(CLF_N_EPOCHS)):\n",
    "    with torch.no_grad():\n",
    "        for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=CLF_BATCH_SIZE, shuffle=False)):\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            y_hat = ext_clf(x)\n",
    "            xe_l = xe_loss(y_hat,y)\n",
    "            total_l = total_loss(xe_l)\n",
    "            acc = (y_hat.argmax(dim=1)==y).to(torch.float).mean()\n",
    "            test_history[\"epoch\"].append(e)\n",
    "            test_history[\"batch\"].append(b)\n",
    "            test_history[\"clf_xe_loss\"].append(xe_l.detach().cpu().numpy().mean().item())\n",
    "            test_history[\"clf_acc\"].append(acc.detach().cpu().numpy().mean().item())\n",
    "            test_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())\n",
    "\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_train, batch_size=CLF_BATCH_SIZE, shuffle=True)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        ext_clf_opt.zero_grad()\n",
    "        y_hat = ext_clf(x)\n",
    "        xe_l = xe_loss(y_hat,y)\n",
    "        total_l = total_loss(xe_l)\n",
    "        total_l.backward()\n",
    "        ext_clf_opt.step()\n",
    "        with torch.no_grad():\n",
    "            acc = (y_hat.argmax(dim=1)==y).to(torch.float).mean()\n",
    "        train_history[\"epoch\"].append(e)\n",
    "        train_history[\"batch\"].append(b)\n",
    "        train_history[\"clf_xe_loss\"].append(xe_l.detach().cpu().numpy().mean().item())\n",
    "        train_history[\"clf_acc\"].append(acc.detach().cpu().numpy().mean().item())\n",
    "        train_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=CLF_BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        y_hat = ext_clf(x)\n",
    "        xe_l = xe_loss(y_hat,y)\n",
    "        total_l = total_loss(xe_l)\n",
    "        acc = (y_hat.argmax(dim=1)==y).to(torch.float).mean()\n",
    "        test_history[\"epoch\"].append(N_EPOCHS)\n",
    "        test_history[\"batch\"].append(b)\n",
    "        test_history[\"clf_xe_loss\"].append(xe_l.detach().cpu().numpy().mean().item())\n",
    "        test_history[\"clf_acc\"].append(acc.detach().cpu().numpy().mean().item())\n",
    "        test_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_history)\n",
    "train_df[\"batch_in_epoch\"] = train_df[\"epoch\"] + train_df[\"batch\"]/train_df[\"batch\"].max()\n",
    "test_df = pd.DataFrame(test_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"total_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} Final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"clf_xe_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"clf_acc\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} Final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_AE(nn.Module):\n",
    "    def __init__(self, in_channels = 1, hidden_channels = 2):\n",
    "        super(MNIST_AE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            CNN(in_channels,[32,64,64,64],[3,3,3,3],[1,2,1,1],[1,1,1,1]),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*dset_img_dim_half*dset_img_dim_half,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,hidden_channels),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_channels,64*dset_img_dim_half*dset_img_dim_half),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1,(64,14,14)),\n",
    "            DeCNN(64,[32],[3],[2],[1],[1]),\n",
    "            CNN(32,[in_channels],[3],[1],[1],nonlinearities=[nn.Sigmoid])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconstrained Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"U-AE\"\n",
    "\n",
    "model = MNIST_AE(mnist_n_channels,AE_LATENT_DIM)\n",
    "if torch.cuda.is_available(): model.cuda()\n",
    "\n",
    "opt = optim.Adam(model.parameters())\n",
    "\n",
    "bce_loss = lambda inp,tgt: torch.sum(F.binary_cross_entropy(inp,tgt,reduction=\"none\"), dim=list(range(1,len(inp.shape))))\n",
    "total_loss = lambda bce_l: torch.mean(torch.concat([bce_l,]))\n",
    "\n",
    "train_history = {\n",
    "    \"epoch\": [],\n",
    "    \"batch\": [],\n",
    "    \"rec_bce_loss\": [],\n",
    "    \"total_loss\": [],\n",
    "}\n",
    "test_history = {\n",
    "    \"epoch\": [],\n",
    "    \"batch\": [],\n",
    "    \"rec_bce_loss\": [],\n",
    "    \"total_loss\": [],\n",
    "}\n",
    "\n",
    "for e in tqdm(range(N_EPOCHS)):\n",
    "    with torch.no_grad():\n",
    "        for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            x_hat = model(x)\n",
    "            bce_l = bce_loss(x_hat,x)\n",
    "            total_l = total_loss(bce_l)\n",
    "            test_history[\"epoch\"].append(e)\n",
    "            test_history[\"batch\"].append(b)\n",
    "            test_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "            test_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())\n",
    "\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        opt.zero_grad()\n",
    "        x_hat = model(x)\n",
    "        bce_l = bce_loss(x_hat,x)\n",
    "        total_l = total_loss(bce_l)\n",
    "        total_l.backward()\n",
    "        opt.step()\n",
    "        train_history[\"epoch\"].append(e)\n",
    "        train_history[\"batch\"].append(b)\n",
    "        train_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "        train_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        x_hat = model(x)\n",
    "        bce_l = bce_loss(x_hat,x)\n",
    "        total_l = total_loss(bce_l)\n",
    "        test_history[\"epoch\"].append(N_EPOCHS)\n",
    "        test_history[\"batch\"].append(b)\n",
    "        test_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "        test_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_history)\n",
    "train_df[\"batch_in_epoch\"] = train_df[\"epoch\"] + train_df[\"batch\"]/train_df[\"batch\"].max()\n",
    "test_df = pd.DataFrame(test_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"total_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} Final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"rec_bce_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        zs.append(model.encoder(x).detach().cpu().numpy())\n",
    "z_train = np.concatenate(tuple(zs),axis=0)\n",
    "z_train.shape, mnist_train.targets.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        zs.append(model.encoder(x).detach().cpu().numpy())\n",
    "z_test = np.concatenate(tuple(zs),axis=0)\n",
    "z_test.shape, mnist_test.targets.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "x_train, y_train = z_train[:,0], z_train[:,1]\n",
    "hue_train = mnist_train.targets.numpy()\n",
    "\n",
    "x_test, y_test = z_test[:,0], z_test[:,1]\n",
    "hue_test = mnist_test.targets.numpy()\n",
    "\n",
    "sns.scatterplot(x=x_train, y=y_train, hue=class_names[hue_train], hue_order=class_names, marker=\"x\", s=4, ax=axes[0], legend=False,)\n",
    "sns.histplot(x=x_train, y=y_train, bins=64, pthresh=0.01, hue=class_names[hue_train], hue_order=class_names, ax=axes[0], legend=False,)\n",
    "sns.kdeplot(x=x_train, y=y_train, levels=5, hue=class_names[hue_train], hue_order=class_names, linewidths=1, ax=axes[0], legend=False,)\n",
    "\n",
    "sns.scatterplot(x=x_test, y=y_test, hue=class_names[hue_test], hue_order=class_names, marker=\"x\", s=4, ax=axes[1],)\n",
    "sns.histplot(x=x_test, y=y_test, bins=64, pthresh=0.01, hue=class_names[hue_test], hue_order=class_names, ax=axes[1],)\n",
    "sns.kdeplot(x=x_test, y=y_test, levels=5, hue=class_names[hue_test], hue_order=class_names, linewidths=1, ax=axes[1],)\n",
    "\n",
    "sns.move_legend(axes[1], \"upper left\", bbox_to_anchor=(1, 0.75),)\n",
    "\n",
    "plt.suptitle(f\"{model_name} latent space distribution\")\n",
    "axes[0].set_title(f\"Train\")\n",
    "axes[1].set_title(f\"Test\")\n",
    "\n",
    "if SAVE_IMAGES:\n",
    "    xlim = axes[0].get_xlim()\n",
    "    ylim = axes[0].get_ylim()\n",
    "    axes[0].set_xlim(max(xlim[0],-20),min(xlim[1],20))\n",
    "    axes[0].set_ylim(max(ylim[0],-20),min(ylim[1],20))\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-z-zoom.{fmt}\"), bbox_inches=\"tight\",)\n",
    "    axes[0].set_xlim(xlim)\n",
    "    axes[0].set_ylim(ylim)\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-z.{fmt}\"), bbox_inches=\"tight\",)\n",
    "\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdes = {}\n",
    "for ci, c in enumerate(class_names):\n",
    "    kdes[c] = sps.gaussian_kde(z_train[hue_train==ci,].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins, maxs = z_train.min(axis=0,keepdims=True), z_train.max(axis=0,keepdims=True)\n",
    "xx, yy = np.meshgrid(*[np.linspace(mins[:,i],maxs[:,i],NUM_POINTS_GRID) for i in range(2)])\n",
    "points = np.vstack([xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "for ci, c in enumerate(class_names):\n",
    "    probs.append(kdes[c](points))\n",
    "probs = np.vstack(probs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Samples from point grid 1-class KDEs\")\n",
    "axes[0,0].set_title(\"Best\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    c_prob = probs[:,ci]\n",
    "    top_threshold = np.quantile(c_prob[c_prob>0],TOP_PCT_TO_SAMPLE_FROM)\n",
    "    supersample_size = max((c_prob>top_threshold).sum(),NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "    c_prob_argsort = c_prob.argsort()\n",
    "    best_and_rest_from_top_pct = [\n",
    "        c_prob_argsort[-1],\n",
    "        *take(\n",
    "            NUMBER_OF_SAMPLES_PER_CLASS-1,\n",
    "            [\n",
    "                x for x in np.random.choice(\n",
    "                    c_prob_argsort[-supersample_size:],\n",
    "                    NUMBER_OF_SAMPLES_PER_CLASS,\n",
    "                    replace=supersample_size==NUMBER_OF_SAMPLES_PER_CLASS,\n",
    "                ) if x != c_prob_argsort[-1] or supersample_size==NUMBER_OF_SAMPLES_PER_CLASS\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    z_np = points.T[best_and_rest_from_top_pct,:]\n",
    "    z = torch.tensor(z_np)\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-pointgrid-1c.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_probs = torch.softmax(torch.tensor(np.log(probs))/SOFTMAX_REPARAM_TEMPERATURE,1).numpy()\n",
    "softmax_classes = class_names[np.argmax(softmax_probs*probs, axis=1)]\n",
    "pd.value_counts(softmax_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from softmax of point grid 1-class KDE\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    indexes_of_this_class = np.logical_and(\n",
    "        softmax_classes==c,\n",
    "        probs[:,ci]>0\n",
    "    )\n",
    "    num_points_in_this_class = indexes_of_this_class.sum()\n",
    "    num_show = min(NUMBER_OF_SAMPLES_PER_CLASS,num_points_in_this_class)\n",
    "    if num_points_in_this_class>0:\n",
    "        points_in_this_class = points.T[indexes_of_this_class,:]\n",
    "        random_points_from_this_class = points_in_this_class[\n",
    "            np.random.choice(\n",
    "                num_points_in_this_class,\n",
    "                num_show,\n",
    "                replace=False,\n",
    "            )\n",
    "        ]\n",
    "        z_np = random_points_from_this_class\n",
    "        z = torch.tensor(z_np)\n",
    "        if torch.cuda.is_available(): z = z.cuda()\n",
    "        x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "        x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(\n",
    "            (\n",
    "                x_hat[pi]\n",
    "                if pi<num_show else\n",
    "                np.zeros((dset_img_dim,dset_img_dim,1))\n",
    "            ),\n",
    "            vmin=0, vmax=1, cmap=\"gray\"\n",
    "        )\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        if pi<num_show:\n",
    "            ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "                size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-pointgrid-1c-softmax.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from the KDE estimators\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    z_np = kdes[c].resample(NUMBER_OF_SAMPLES_PER_CLASS).T.astype(np.float32)\n",
    "    z = torch.tensor(z_np)\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-kde-1c.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayopts = {}\n",
    "for ci, c in enumerate(class_names):\n",
    "    bayopts[ci] = nll_optimizer_for(ci,\n",
    "                                model.decoder,\n",
    "                                ext_clf,\n",
    "                                bounds=[\n",
    "                                    (min(mins[0,i],-4.0), max(maxs[0,i],4.0))\n",
    "                                    for i in range(mins.shape[1])\n",
    "                                ],\n",
    "                                )\n",
    "    bayopts[ci].run_optimization(max_iter=BAYESIAN_OPTIMISATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ci, c in enumerate(class_names):\n",
    "    if SAVE_IMAGES:\n",
    "        # Why do they show the image inside the function???\n",
    "        for fmt in IMAGE_FORMATS:\n",
    "            bayopts[ci].plot_acquisition(filename=osp.join(images_folder,fmt,f\"{model_name}-bayes-acquisition-{ci}.{fmt}\"))\n",
    "            plt.close()\n",
    "    if SHOW_ACQUISITIONS:\n",
    "        print(c)\n",
    "        bayopts[ci].plot_acquisition()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from the Bayesian Optimisation\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    top_idx = np.argsort(bayopts[ci].Y, axis=0).ravel()\n",
    "    z_np = bayopts[ci].X[top_idx].astype(np.float32)\n",
    "    z = torch.tensor(z_np)\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-bayesian-extclf.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrained Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"C-AE\"\n",
    "\n",
    "model = MNIST_AE(mnist_n_channels,AE_LATENT_DIM)\n",
    "clf = MLP(AE_LATENT_DIM,[128,128,mnist_n_classes], drop_last_nonlinearity=True)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    clf.cuda()\n",
    "\n",
    "opt = optim.Adam(chain(model.parameters(),clf.parameters()))\n",
    "\n",
    "bce_loss = lambda inp,tgt: torch.sum(F.binary_cross_entropy(inp,tgt,reduction=\"none\"), dim=list(range(1,len(inp.shape))))\n",
    "xe_loss = nn.CrossEntropyLoss()\n",
    "total_loss = lambda bce_l, xe_loss: 20*xe_loss + torch.mean(torch.concat([bce_l,]))\n",
    "\n",
    "train_history = {\n",
    "    \"epoch\": [],\n",
    "    \"batch\": [],\n",
    "    \"rec_bce_loss\": [],\n",
    "    \"clf_xe_loss\": [],\n",
    "    \"total_loss\": [],\n",
    "}\n",
    "test_history = {\n",
    "    \"epoch\": [],\n",
    "    \"batch\": [],\n",
    "    \"rec_bce_loss\": [],\n",
    "    \"clf_xe_loss\": [],\n",
    "    \"total_loss\": [],\n",
    "}\n",
    "\n",
    "for e in tqdm(range(N_EPOCHS)):\n",
    "    with torch.no_grad():\n",
    "        for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            z = model.encoder(x)\n",
    "            y_hat = clf(z)\n",
    "            x_hat = model.decoder(z)\n",
    "            bce_l = bce_loss(x_hat,x)\n",
    "            xe_l = xe_loss(y_hat,y)\n",
    "            total_l = total_loss(bce_l,xe_l)\n",
    "            test_history[\"epoch\"].append(e)\n",
    "            test_history[\"batch\"].append(b)\n",
    "            test_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "            test_history[\"clf_xe_loss\"].append(xe_l.detach().cpu().numpy().mean().item())\n",
    "            test_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())\n",
    "\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        opt.zero_grad()\n",
    "        z = model.encoder(x)\n",
    "        y_hat = clf(z)\n",
    "        x_hat = model.decoder(z)\n",
    "        bce_l = bce_loss(x_hat,x)\n",
    "        xe_l = xe_loss(y_hat,y)\n",
    "        total_l = total_loss(bce_l,xe_l)\n",
    "        total_l.backward()\n",
    "        opt.step()\n",
    "        train_history[\"epoch\"].append(e)\n",
    "        train_history[\"batch\"].append(b)\n",
    "        train_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "        train_history[\"clf_xe_loss\"].append(xe_l.detach().cpu().numpy().mean().item())\n",
    "        train_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        z = model.encoder(x)\n",
    "        y_hat = clf(z)\n",
    "        x_hat = model.decoder(z)\n",
    "        bce_l = bce_loss(x_hat,x)\n",
    "        xe_l = xe_loss(y_hat,y)\n",
    "        total_l = total_loss(bce_l,xe_l)\n",
    "        test_history[\"epoch\"].append(N_EPOCHS)\n",
    "        test_history[\"batch\"].append(b)\n",
    "        test_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "        test_history[\"clf_xe_loss\"].append(xe_l.detach().cpu().numpy().mean().item())\n",
    "        test_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_history)\n",
    "train_df[\"batch_in_epoch\"] = train_df[\"epoch\"] + train_df[\"batch\"]/train_df[\"batch\"].max()\n",
    "test_df = pd.DataFrame(test_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"total_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"rec_bce_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"clf_xe_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        zs.append(model.encoder(x).detach().cpu().numpy())\n",
    "z_train = np.concatenate(tuple(zs),axis=0)\n",
    "z_train.shape, mnist_train.targets.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        zs.append(model.encoder(x).detach().cpu().numpy())\n",
    "z_test = np.concatenate(tuple(zs),axis=0)\n",
    "z_test.shape, mnist_test.targets.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "x_train, y_train = z_train[:,0], z_train[:,1]\n",
    "hue_train = mnist_train.targets.numpy()\n",
    "\n",
    "x_test, y_test = z_test[:,0], z_test[:,1]\n",
    "hue_test = mnist_test.targets.numpy()\n",
    "\n",
    "sns.scatterplot(x=x_train, y=y_train, hue=class_names[hue_train], hue_order=class_names, marker=\"x\", s=4, ax=axes[0], legend=False,)\n",
    "sns.histplot(x=x_train, y=y_train, bins=64, pthresh=0.01, hue=class_names[hue_train], hue_order=class_names, ax=axes[0], legend=False,)\n",
    "kde_train = sns.kdeplot(x=x_train, y=y_train, levels=5, hue=class_names[hue_train], hue_order=class_names, linewidths=1, ax=axes[0], legend=False,)\n",
    "\n",
    "sns.scatterplot(x=x_test, y=y_test, hue=class_names[hue_test], hue_order=class_names, marker=\"x\", s=4, ax=axes[1],)\n",
    "sns.histplot(x=x_test, y=y_test, bins=64, pthresh=0.01, hue=class_names[hue_test], hue_order=class_names, ax=axes[1],)\n",
    "kde_test = sns.kdeplot(x=x_test, y=y_test, levels=5, hue=class_names[hue_test], hue_order=class_names, linewidths=1, ax=axes[1],)\n",
    "\n",
    "sns.move_legend(axes[1], \"upper left\", bbox_to_anchor=(1, 0.75),)\n",
    "\n",
    "plt.suptitle(f\"{model_name} latent space distribution\")\n",
    "axes[0].set_title(f\"Train\")\n",
    "axes[1].set_title(f\"Test\")\n",
    "\n",
    "if SAVE_IMAGES:\n",
    "    xlim = axes[0].get_xlim()\n",
    "    ylim = axes[0].get_ylim()\n",
    "    axes[0].set_xlim(max(xlim[0],-20),min(xlim[1],20))\n",
    "    axes[0].set_ylim(max(ylim[0],-20),min(ylim[1],20))\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-z-zoom.{fmt}\"), bbox_inches=\"tight\",)\n",
    "    axes[0].set_xlim(xlim)\n",
    "    axes[0].set_ylim(ylim)\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-z.{fmt}\"), bbox_inches=\"tight\",)\n",
    "\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdes = {}\n",
    "for ci, c in enumerate(class_names):\n",
    "    kdes[c] = sps.gaussian_kde(z_train[hue_train==ci,].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins, maxs = z_train.min(axis=0,keepdims=True), z_train.max(axis=0,keepdims=True)\n",
    "xx, yy = np.meshgrid(*[np.linspace(mins[:,i],maxs[:,i],NUM_POINTS_GRID) for i in range(2)])\n",
    "points = np.vstack([xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "for ci, c in enumerate(class_names):\n",
    "    probs.append(kdes[c](points))\n",
    "probs = np.vstack(probs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Samples from point grid 1-class KDEs\")\n",
    "axes[0,0].set_title(\"Best\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    c_prob = probs[:,ci]\n",
    "    top_threshold = np.quantile(c_prob[c_prob>0],TOP_PCT_TO_SAMPLE_FROM)\n",
    "    supersample_size = max((c_prob>top_threshold).sum(),NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "    c_prob_argsort = c_prob.argsort()\n",
    "    best_and_rest_from_top_pct = [\n",
    "        c_prob_argsort[-1],\n",
    "        *take(\n",
    "            NUMBER_OF_SAMPLES_PER_CLASS-1,\n",
    "            [\n",
    "                x for x in np.random.choice(\n",
    "                    c_prob_argsort[-supersample_size:],\n",
    "                    NUMBER_OF_SAMPLES_PER_CLASS,\n",
    "                    replace=supersample_size==NUMBER_OF_SAMPLES_PER_CLASS,\n",
    "                ) if x != c_prob_argsort[-1] or supersample_size==NUMBER_OF_SAMPLES_PER_CLASS\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    z_np = points.T[best_and_rest_from_top_pct,:]\n",
    "    z = torch.tensor(z_np)\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-pointgrid-1c.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_probs = torch.softmax(torch.tensor(np.log(probs))/SOFTMAX_REPARAM_TEMPERATURE,1).numpy()\n",
    "softmax_classes = class_names[np.argmax(softmax_probs*probs, axis=1)]\n",
    "pd.value_counts(softmax_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from softmax of point grid 1-class KDE\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    indexes_of_this_class = np.logical_and(\n",
    "        softmax_classes==c,\n",
    "        probs[:,ci]>0\n",
    "    )\n",
    "    num_points_in_this_class = indexes_of_this_class.sum()\n",
    "    num_show = min(NUMBER_OF_SAMPLES_PER_CLASS,num_points_in_this_class)\n",
    "    if num_points_in_this_class>0:\n",
    "        points_in_this_class = points.T[indexes_of_this_class,:]\n",
    "        random_points_from_this_class = points_in_this_class[\n",
    "            np.random.choice(\n",
    "                num_points_in_this_class,\n",
    "                num_show,\n",
    "                replace=False,\n",
    "            )\n",
    "        ]\n",
    "        z_np = random_points_from_this_class\n",
    "        z = torch.tensor(z_np)\n",
    "        if torch.cuda.is_available(): z = z.cuda()\n",
    "        x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "        x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(\n",
    "            (\n",
    "                x_hat[pi]\n",
    "                if pi<num_show else\n",
    "                np.zeros((dset_img_dim,dset_img_dim,1))\n",
    "            ),\n",
    "            vmin=0, vmax=1, cmap=\"gray\"\n",
    "        )\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        if pi<num_show:\n",
    "            ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "                size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-pointgrid-1c-softmax.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from the KDE estimators\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    z_np = kdes[c].resample(NUMBER_OF_SAMPLES_PER_CLASS).T.astype(np.float32)\n",
    "    z = torch.tensor(z_np)\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-kde-1c.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayopts = {}\n",
    "for ci, c in enumerate(class_names):\n",
    "    bayopts[ci] = nll_optimizer_for(ci,\n",
    "                                model.decoder,\n",
    "                                ext_clf,\n",
    "                                bounds=[\n",
    "                                    (min(mins[0,i],-4.0), max(maxs[0,i],4.0))\n",
    "                                    for i in range(mins.shape[1])\n",
    "                                ],\n",
    "                                )\n",
    "    bayopts[ci].run_optimization(max_iter=BAYESIAN_OPTIMISATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ci, c in enumerate(class_names):\n",
    "    if SAVE_IMAGES:\n",
    "        # Why do they show the image inside the function???\n",
    "        for fmt in IMAGE_FORMATS:\n",
    "            bayopts[ci].plot_acquisition(filename=osp.join(images_folder,fmt,f\"{model_name}-bayes-acquisition-{ci}.{fmt}\"))\n",
    "            plt.close()\n",
    "    if SHOW_ACQUISITIONS:\n",
    "        print(c)\n",
    "        bayopts[ci].plot_acquisition()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from the Bayesian Optimisation\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    top_idx = np.argsort(bayopts[ci].Y, axis=0).ravel()\n",
    "    z_np = bayopts[ci].X[top_idx].astype(np.float32)\n",
    "    z = torch.tensor(z_np)\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-bayesian-extclf.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(mean:torch.Tensor, log_var:torch.Tensor) -> torch.Tensor:\n",
    "    sigma = torch.sqrt(torch.exp(log_var))\n",
    "    epsilon = torch.normal(mean=0., std=1., size=mean.shape, device=mean.device)\n",
    "    return mean + sigma * epsilon\n",
    "\n",
    "\n",
    "def kl_div(mean:torch.Tensor, log_var:torch.Tensor) -> torch.Tensor:\n",
    "    # Regularization term (KL divergence)\n",
    "    kl_l = -0.5 * torch.sum(1 + log_var \\\n",
    "                             - torch.square(mean) \\\n",
    "                             - torch.exp(log_var), axis=-1)\n",
    "    \n",
    "    return kl_l\n",
    "\n",
    "class MNIST_VAE(nn.Module):\n",
    "    def __init__(self, in_channels = 1, hidden_channels = 2):\n",
    "        super(MNIST_VAE, self).__init__()\n",
    "\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            CNN(in_channels,[32,64,64,64],[3,3,3,3],[1,2,1,1],[1,1,1,1]),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*dset_img_dim_half*dset_img_dim_half,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2*hidden_channels),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_channels,64*dset_img_dim_half*dset_img_dim_half),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1,(64,14,14)),\n",
    "            DeCNN(64,[32],[3],[2],[1],[1]),\n",
    "            CNN(32,[in_channels],[3],[1],[1],nonlinearities=[nn.Sigmoid])\n",
    "        )\n",
    "    \n",
    "    def get_mu_and_sigma(self, x):\n",
    "        mu_and_sigma = self.encoder(x)\n",
    "        mu, sigma = mu_and_sigma[:,:self.hidden_channels], mu_and_sigma[:,self.hidden_channels:]\n",
    "        return mu, sigma\n",
    "    \n",
    "    def sample(self, mu, sigma):\n",
    "        z = sample(mu, sigma)\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        img = self.decoder(z)\n",
    "        return img\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(\n",
    "            self.sample(\n",
    "                *self.get_mu_and_sigma(x)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"U-VAE\"\n",
    "\n",
    "model = MNIST_VAE(mnist_n_channels,AE_LATENT_DIM)\n",
    "if torch.cuda.is_available(): model.cuda()\n",
    "\n",
    "opt = optim.Adam(model.parameters())\n",
    "\n",
    "bce_loss = lambda inp,tgt: torch.sum(F.binary_cross_entropy(inp,tgt,reduction=\"none\"), dim=list(range(1,len(inp.shape)))) #nn.BCELoss(reduction=\"sum\")\n",
    "kl_loss = lambda mu, sigma: kl_div(mu, sigma)\n",
    "total_loss = lambda bce_l, kl_l: torch.mean(torch.concat([bce_l, kl_l]))\n",
    "\n",
    "train_history = {\n",
    "    \"epoch\": [],\n",
    "    \"batch\": [],\n",
    "    \"rec_bce_loss\": [],\n",
    "    \"kl_loss\": [],\n",
    "    \"total_loss\": [],\n",
    "}\n",
    "test_history = {\n",
    "    \"epoch\": [],\n",
    "    \"batch\": [],\n",
    "    \"rec_bce_loss\": [],\n",
    "    \"kl_loss\": [],\n",
    "    \"total_loss\": [],\n",
    "}\n",
    "\n",
    "for e in tqdm(range(N_EPOCHS)):\n",
    "    with torch.no_grad():\n",
    "        for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            mu, sigma = model.get_mu_and_sigma(x)\n",
    "            z = model.sample(mu, sigma)\n",
    "            x_hat = model.decode(z)\n",
    "            bce_l = bce_loss(x_hat,x)\n",
    "            kl_l = kl_loss(mu, sigma)\n",
    "            total_l = total_loss(bce_l,kl_l)\n",
    "            test_history[\"epoch\"].append(e)\n",
    "            test_history[\"batch\"].append(b)\n",
    "            test_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "            test_history[\"kl_loss\"].append(kl_l.detach().cpu().numpy().mean().item())\n",
    "            test_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())\n",
    "\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        opt.zero_grad()\n",
    "        mu, sigma = model.get_mu_and_sigma(x)\n",
    "        z = model.sample(mu, sigma)\n",
    "        x_hat = model.decode(z)\n",
    "        bce_l = bce_loss(x_hat,x)\n",
    "        kl_l = kl_loss(mu, sigma)\n",
    "        total_l = total_loss(bce_l,kl_l)\n",
    "        total_l.backward()\n",
    "        opt.step()\n",
    "        train_history[\"epoch\"].append(e)\n",
    "        train_history[\"batch\"].append(b)\n",
    "        train_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "        train_history[\"kl_loss\"].append(kl_l.detach().cpu().numpy().mean().item())\n",
    "        train_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        mu, sigma = model.get_mu_and_sigma(x)\n",
    "        z = model.sample(mu, sigma)\n",
    "        x_hat = model.decode(z)\n",
    "        bce_l = bce_loss(x_hat,x)\n",
    "        kl_l = kl_loss(mu, sigma)\n",
    "        total_l = total_loss(bce_l,kl_l)\n",
    "        test_history[\"epoch\"].append(N_EPOCHS)\n",
    "        test_history[\"batch\"].append(b)\n",
    "        test_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "        test_history[\"kl_loss\"].append(kl_l.detach().cpu().numpy().mean().item())\n",
    "        test_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_history)\n",
    "train_df[\"batch_in_epoch\"] = train_df[\"epoch\"] + train_df[\"batch\"]/train_df[\"batch\"].max()\n",
    "test_df = pd.DataFrame(test_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"total_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} Final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"rec_bce_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"kl_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        zs.append(model.encoder(x).detach().cpu().numpy()[:,:2])\n",
    "z_train = np.concatenate(tuple(zs),axis=0)\n",
    "z_train.shape, mnist_train.targets.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        zs.append(model.encoder(x).detach().cpu().numpy()[:,:2])\n",
    "z_test = np.concatenate(tuple(zs),axis=0)\n",
    "z_test.shape, mnist_test.targets.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "x_train, y_train = z_train[:,0], z_train[:,1]\n",
    "hue_train = mnist_train.targets.numpy()\n",
    "\n",
    "x_test, y_test = z_test[:,0], z_test[:,1]\n",
    "hue_test = mnist_test.targets.numpy()\n",
    "\n",
    "sns.scatterplot(x=x_train, y=y_train, hue=class_names[hue_train], hue_order=class_names, marker=\"x\", s=4, ax=axes[0], legend=False,)\n",
    "sns.histplot(x=x_train, y=y_train, bins=64, pthresh=0.01, hue=class_names[hue_train], hue_order=class_names, ax=axes[0], legend=False,)\n",
    "sns.kdeplot(x=x_train, y=y_train, levels=5, hue=class_names[hue_train], hue_order=class_names, linewidths=1, ax=axes[0], legend=False,)\n",
    "\n",
    "sns.scatterplot(x=x_test, y=y_test, hue=class_names[hue_test], hue_order=class_names, marker=\"x\", s=4, ax=axes[1],)\n",
    "sns.histplot(x=x_test, y=y_test, bins=64, pthresh=0.01, hue=class_names[hue_test], hue_order=class_names, ax=axes[1],)\n",
    "sns.kdeplot(x=x_test, y=y_test, levels=5, hue=class_names[hue_test], hue_order=class_names, linewidths=1, ax=axes[1],)\n",
    "\n",
    "sns.move_legend(axes[1], \"upper left\", bbox_to_anchor=(1, 0.75),)\n",
    "\n",
    "plt.suptitle(f\"{model_name} latent space distribution\")\n",
    "axes[0].set_title(f\"Train\")\n",
    "axes[1].set_title(f\"Test\")\n",
    "\n",
    "if SAVE_IMAGES:\n",
    "    xlim = axes[0].get_xlim()\n",
    "    ylim = axes[0].get_ylim()\n",
    "    axes[0].set_xlim(max(xlim[0],-1),min(xlim[1],1))\n",
    "    axes[0].set_ylim(max(ylim[0],-1),min(ylim[1],1))\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-z-zoom.{fmt}\"), bbox_inches=\"tight\",)\n",
    "    axes[0].set_xlim(xlim)\n",
    "    axes[0].set_ylim(ylim)\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-z.{fmt}\"), bbox_inches=\"tight\",)\n",
    "\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdes = {}\n",
    "for ci, c in enumerate(class_names):\n",
    "    kdes[c] = sps.gaussian_kde(z_train[hue_train==ci,].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins, maxs = z_train.min(axis=0,keepdims=True), z_train.max(axis=0,keepdims=True)\n",
    "xx, yy = np.meshgrid(*[np.linspace(mins[:,i],maxs[:,i],NUM_POINTS_GRID) for i in range(2)])\n",
    "points = np.vstack([xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "for ci, c in enumerate(class_names):\n",
    "    probs.append(kdes[c](points))\n",
    "probs = np.vstack(probs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Samples from point grid 1-class KDEs\")\n",
    "axes[0,0].set_title(\"Best\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    c_prob = probs[:,ci]\n",
    "    top_threshold = np.quantile(c_prob[c_prob>0],TOP_PCT_TO_SAMPLE_FROM)\n",
    "    supersample_size = max((c_prob>top_threshold).sum(),NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "    c_prob_argsort = c_prob.argsort()\n",
    "    best_and_rest_from_top_pct = [\n",
    "        c_prob_argsort[-1],\n",
    "        *take(\n",
    "            NUMBER_OF_SAMPLES_PER_CLASS-1,\n",
    "            [\n",
    "                x for x in np.random.choice(\n",
    "                    c_prob_argsort[-supersample_size:],\n",
    "                    NUMBER_OF_SAMPLES_PER_CLASS,\n",
    "                    replace=supersample_size==NUMBER_OF_SAMPLES_PER_CLASS,\n",
    "                ) if x != c_prob_argsort[-1] or supersample_size==NUMBER_OF_SAMPLES_PER_CLASS\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    z_np = points.T[best_and_rest_from_top_pct,:]\n",
    "    z = torch.tensor(z_np)\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-pointgrid-1c.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_probs = torch.softmax(torch.tensor(np.log(probs))/SOFTMAX_REPARAM_TEMPERATURE,1).numpy()\n",
    "softmax_classes = np.array(class_names)[np.argmax(softmax_probs*probs, axis=1)]\n",
    "pd.value_counts(softmax_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from softmax of point grid 1-class KDE\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    indexes_of_this_class = np.logical_and(\n",
    "        softmax_classes==c,\n",
    "        probs[:,ci]>0\n",
    "    )\n",
    "    num_points_in_this_class = indexes_of_this_class.sum()\n",
    "    num_show = min(NUMBER_OF_SAMPLES_PER_CLASS,num_points_in_this_class)\n",
    "    if num_points_in_this_class>0:\n",
    "        points_in_this_class = points.T[indexes_of_this_class,:]\n",
    "        random_points_from_this_class = points_in_this_class[\n",
    "            np.random.choice(\n",
    "                num_points_in_this_class,\n",
    "                num_show,\n",
    "                replace=False,\n",
    "            )\n",
    "        ]\n",
    "        z_np = random_points_from_this_class\n",
    "        z = torch.tensor(z_np)\n",
    "        if torch.cuda.is_available(): z = z.cuda()\n",
    "        x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "        x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(\n",
    "            (\n",
    "                x_hat[pi]\n",
    "                if pi<num_show else\n",
    "                np.zeros((dset_img_dim,dset_img_dim,1))\n",
    "            ),\n",
    "            vmin=0, vmax=1, cmap=\"gray\"\n",
    "        )\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        if pi<num_show:\n",
    "            ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "                size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-pointgrid-1c-softmax.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from the KDE estimators\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    z = torch.tensor(kdes[c].resample(NUMBER_OF_SAMPLES_PER_CLASS).T.astype(np.float32))\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-kde-1c.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayopts = {}\n",
    "for ci, c in enumerate(class_names):\n",
    "    bayopts[ci] = nll_optimizer_for(ci,\n",
    "                                model.decoder,\n",
    "                                ext_clf,\n",
    "                                bounds=[\n",
    "                                    (min(mins[0,i],-4.0), max(maxs[0,i],4.0))\n",
    "                                    for i in range(mins.shape[1])\n",
    "                                ],\n",
    "                                )\n",
    "    bayopts[ci].run_optimization(max_iter=BAYESIAN_OPTIMISATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ci, c in enumerate(class_names):\n",
    "    if SAVE_IMAGES:\n",
    "        # Why do they show the image inside the function???\n",
    "        for fmt in IMAGE_FORMATS:\n",
    "            bayopts[ci].plot_acquisition(filename=osp.join(images_folder,fmt,f\"{model_name}-bayes-acquisition-{ci}.{fmt}\"))\n",
    "            plt.close()\n",
    "    if SHOW_ACQUISITIONS:\n",
    "        print(c)\n",
    "        bayopts[ci].plot_acquisition()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from the Bayesian Optimisation\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    top_idx = np.argsort(bayopts[ci].Y, axis=0).ravel()\n",
    "    z_np = bayopts[ci].X[top_idx].astype(np.float32)\n",
    "    z = torch.tensor(z_np)\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-bayesian-extclf.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"C-VAE\"\n",
    "N_EPOCHS = 16\n",
    "BATCH_SIZE = 64\n",
    "AE_LATENT_DIM = 2\n",
    "\n",
    "model = MNIST_VAE(mnist_n_channels,AE_LATENT_DIM)\n",
    "clf = MLP(AE_LATENT_DIM,[128,128,mnist_n_classes], drop_last_nonlinearity=True)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    clf.cuda()\n",
    "\n",
    "opt = optim.Adam(chain(model.parameters(),clf.parameters()))\n",
    "\n",
    "bce_loss = lambda inp,tgt: torch.sum(F.binary_cross_entropy(inp,tgt,reduction=\"none\"), dim=list(range(1,len(inp.shape)))) #nn.BCELoss(reduction=\"sum\")\n",
    "kl_loss = lambda mu, sigma: kl_div(mu, sigma)\n",
    "xe_loss = nn.CrossEntropyLoss()\n",
    "total_loss = lambda bce_l, kl_l, xe_loss: 20*xe_loss + torch.mean(torch.concat([bce_l, kl_l]))\n",
    "#if torch.cuda.is_available():\n",
    "#    bce_loss = bce_loss.cuda()\n",
    "#    xe_loss = xe_loss.cuda()\n",
    "\n",
    "train_history = {\n",
    "    \"epoch\": [],\n",
    "    \"batch\": [],\n",
    "    \"rec_bce_loss\": [],\n",
    "    \"kl_loss\": [],\n",
    "    \"clf_xe_loss\": [],\n",
    "    \"total_loss\": [],\n",
    "}\n",
    "test_history = {\n",
    "    \"epoch\": [],\n",
    "    \"batch\": [],\n",
    "    \"rec_bce_loss\": [],\n",
    "    \"kl_loss\": [],\n",
    "    \"clf_xe_loss\": [],\n",
    "    \"total_loss\": [],\n",
    "}\n",
    "\n",
    "for e in tqdm(range(N_EPOCHS)):\n",
    "    with torch.no_grad():\n",
    "        for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            mu, sigma = model.get_mu_and_sigma(x)\n",
    "            y_hat = clf(mu)\n",
    "            z = model.sample(mu, sigma)\n",
    "            x_hat = model.decode(z)\n",
    "            bce_l = bce_loss(x_hat,x)\n",
    "            kl_l = kl_loss(mu, sigma)\n",
    "            xe_l = xe_loss(y_hat,y)\n",
    "            total_l = total_loss(bce_l,kl_l,xe_l)\n",
    "            test_history[\"epoch\"].append(e)\n",
    "            test_history[\"batch\"].append(b)\n",
    "            test_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "            test_history[\"kl_loss\"].append(kl_l.detach().cpu().numpy().mean().item())\n",
    "            test_history[\"clf_xe_loss\"].append(xe_l.detach().cpu().numpy().mean().item())\n",
    "            test_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())\n",
    "\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        opt.zero_grad()\n",
    "        mu, sigma = model.get_mu_and_sigma(x)\n",
    "        y_hat = clf(mu)\n",
    "        z = model.sample(mu, sigma)\n",
    "        x_hat = model.decode(z)\n",
    "        bce_l = bce_loss(x_hat,x)\n",
    "        kl_l = kl_loss(mu, sigma)\n",
    "        xe_l = xe_loss(y_hat,y)\n",
    "        total_l = total_loss(bce_l,kl_l,xe_l)\n",
    "        total_l.backward()\n",
    "        opt.step()\n",
    "        train_history[\"epoch\"].append(e)\n",
    "        train_history[\"batch\"].append(b)\n",
    "        train_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "        train_history[\"kl_loss\"].append(kl_l.detach().cpu().numpy().mean().item())\n",
    "        train_history[\"clf_xe_loss\"].append(xe_l.detach().cpu().numpy().mean().item())\n",
    "        train_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        mu, sigma = model.get_mu_and_sigma(x)\n",
    "        y_hat = clf(mu)\n",
    "        z = model.sample(mu, sigma)\n",
    "        x_hat = model.decode(z)\n",
    "        bce_l = bce_loss(x_hat,x)\n",
    "        kl_l = kl_loss(mu, sigma)\n",
    "        xe_l = xe_loss(y_hat,y)\n",
    "        total_l = total_loss(bce_l,kl_l,xe_l)\n",
    "        test_history[\"epoch\"].append(N_EPOCHS)\n",
    "        test_history[\"batch\"].append(b)\n",
    "        test_history[\"rec_bce_loss\"].append(bce_l.detach().cpu().numpy().mean().item())\n",
    "        test_history[\"kl_loss\"].append(kl_l.detach().cpu().numpy().mean().item())\n",
    "        test_history[\"clf_xe_loss\"].append(xe_l.detach().cpu().numpy().mean().item())\n",
    "        test_history[\"total_loss\"].append(total_l.detach().cpu().numpy().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_history)\n",
    "train_df[\"batch_in_epoch\"] = train_df[\"epoch\"] + train_df[\"batch\"]/train_df[\"batch\"].max()\n",
    "test_df = pd.DataFrame(test_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"total_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"rec_bce_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"kl_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type=\"clf_xe_loss\"\n",
    "train_df.set_index(\"batch_in_epoch\")[loss_type].plot(c=\"b\")\n",
    "ax:plt.Axes = plt.gca()\n",
    "nax = ax.twinx()\n",
    "ax.sharey(nax)\n",
    "test_df.groupby(\"epoch\")[loss_type].mean().plot(c=\"r\")\n",
    "plt.title(f\"{model_name} {loss_type}\")\n",
    "print(f\"{model_name} final {loss_type} tr/val = {train_df.set_index('batch_in_epoch').sort_index(inplace=False,ascending=True)[loss_type].iloc[-1]:.4f}/{test_df.groupby('epoch')[loss_type].mean().sort_index(inplace=False,ascending=True).iloc[-1]:.4f}\")\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-{loss_type}.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        zs.append(model.encoder(x).detach().cpu().numpy()[:,:2])\n",
    "z_train = np.concatenate(tuple(zs),axis=0)\n",
    "z_train.shape, mnist_train.targets.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "with torch.no_grad():\n",
    "    for b, (x, y) in enumerate(DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=False)):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        zs.append(model.encoder(x).detach().cpu().numpy()[:,:2])\n",
    "z_test = np.concatenate(tuple(zs),axis=0)\n",
    "z_test.shape, mnist_test.targets.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "x_train, y_train = z_train[:,0], z_train[:,1]\n",
    "hue_train = mnist_train.targets.numpy()\n",
    "\n",
    "x_test, y_test = z_test[:,0], z_test[:,1]\n",
    "hue_test = mnist_test.targets.numpy()\n",
    "\n",
    "sns.scatterplot(x=x_train, y=y_train, hue=class_names[hue_train], hue_order=class_names, marker=\"x\", s=4, ax=axes[0], legend=False,)\n",
    "sns.histplot(x=x_train, y=y_train, bins=64, pthresh=0.01, hue=class_names[hue_train], hue_order=class_names, ax=axes[0], legend=False,)\n",
    "kde_train = sns.kdeplot(x=x_train, y=y_train, levels=5, hue=class_names[hue_train], hue_order=class_names, linewidths=1, ax=axes[0], legend=False,)\n",
    "\n",
    "sns.scatterplot(x=x_test, y=y_test, hue=class_names[hue_test], hue_order=class_names, marker=\"x\", s=4, ax=axes[1],)\n",
    "sns.histplot(x=x_test, y=y_test, bins=64, pthresh=0.01, hue=class_names[hue_test], hue_order=class_names, ax=axes[1],)\n",
    "kde_test = sns.kdeplot(x=x_test, y=y_test, levels=5, hue=class_names[hue_test], hue_order=class_names, linewidths=1, ax=axes[1],)\n",
    "\n",
    "sns.move_legend(axes[1], \"upper left\", bbox_to_anchor=(1, 0.75),)\n",
    "\n",
    "plt.suptitle(f\"{model_name} latent space distribution\")\n",
    "axes[0].set_title(f\"Train\")\n",
    "axes[1].set_title(f\"Test\")\n",
    "\n",
    "if SAVE_IMAGES:\n",
    "    xlim = axes[0].get_xlim()\n",
    "    ylim = axes[0].get_ylim()\n",
    "    axes[0].set_xlim(max(xlim[0],-1),min(xlim[1],1))\n",
    "    axes[0].set_ylim(max(ylim[0],-1),min(ylim[1],1))\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-z-zoom.{fmt}\"), bbox_inches=\"tight\",)\n",
    "    axes[0].set_xlim(xlim)\n",
    "    axes[0].set_ylim(ylim)\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-z.{fmt}\"), bbox_inches=\"tight\",)\n",
    "\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdes = {}\n",
    "for ci, c in enumerate(class_names):\n",
    "    kdes[c] = sps.gaussian_kde(z_train[hue_train==ci,].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins, maxs = z_train.min(axis=0,keepdims=True), z_train.max(axis=0,keepdims=True)\n",
    "xx, yy = np.meshgrid(*[np.linspace(mins[:,i],maxs[:,i],NUM_POINTS_GRID) for i in range(2)])\n",
    "points = np.vstack([xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "for ci, c in enumerate(class_names):\n",
    "    probs.append(kdes[c](points))\n",
    "probs = np.vstack(probs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Samples from point grid 1-class KDEs\")\n",
    "axes[0,0].set_title(\"Best\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    c_prob = probs[:,ci]\n",
    "    top_threshold = np.quantile(c_prob[c_prob>0],TOP_PCT_TO_SAMPLE_FROM)\n",
    "    supersample_size = max((c_prob>top_threshold).sum(),NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "    c_prob_argsort = c_prob.argsort()\n",
    "    best_and_rest_from_top_pct = [\n",
    "        c_prob_argsort[-1],\n",
    "        *take(\n",
    "            NUMBER_OF_SAMPLES_PER_CLASS-1,\n",
    "            [\n",
    "                x for x in np.random.choice(\n",
    "                    c_prob_argsort[-supersample_size:],\n",
    "                    NUMBER_OF_SAMPLES_PER_CLASS,\n",
    "                    replace=supersample_size==NUMBER_OF_SAMPLES_PER_CLASS,\n",
    "                ) if x != c_prob_argsort[-1] or supersample_size==NUMBER_OF_SAMPLES_PER_CLASS\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    z_np = points.T[best_and_rest_from_top_pct,:]\n",
    "    z = torch.tensor(z_np)\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-pointgrid-1c.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_probs = torch.softmax(torch.tensor(np.log(probs))/SOFTMAX_REPARAM_TEMPERATURE,1).numpy()\n",
    "softmax_classes = np.array(class_names)[np.argmax(softmax_probs*probs, axis=1)]\n",
    "pd.value_counts(softmax_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from softmax of point grid 1-class KDE\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    indexes_of_this_class = np.logical_and(\n",
    "        softmax_classes==c,\n",
    "        probs[:,ci]>0\n",
    "    )\n",
    "    num_points_in_this_class = indexes_of_this_class.sum()\n",
    "    num_show = min(NUMBER_OF_SAMPLES_PER_CLASS,num_points_in_this_class)\n",
    "    if num_points_in_this_class>0:\n",
    "        points_in_this_class = points.T[indexes_of_this_class,:]\n",
    "        random_points_from_this_class = points_in_this_class[\n",
    "            np.random.choice(\n",
    "                num_points_in_this_class,\n",
    "                num_show,\n",
    "                replace=False,\n",
    "            )\n",
    "        ]\n",
    "        z_np = random_points_from_this_class\n",
    "        z = torch.tensor(z_np)\n",
    "        if torch.cuda.is_available(): z = z.cuda()\n",
    "        x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "        x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(\n",
    "            (\n",
    "                x_hat[pi]\n",
    "                if pi<num_show else\n",
    "                np.zeros((dset_img_dim,dset_img_dim,1))\n",
    "            ),\n",
    "            vmin=0, vmax=1, cmap=\"gray\"\n",
    "        )\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        if pi<num_show:\n",
    "            ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "                size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-pointgrid-1c-softmax.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from the KDE estimators\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    z_np = kdes[c].resample(NUMBER_OF_SAMPLES_PER_CLASS).T.astype(np.float32)\n",
    "    z = torch.tensor(z_np)\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-kde-1c.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayopts = {}\n",
    "for ci, c in enumerate(class_names):\n",
    "    bayopts[ci] = nll_optimizer_for(ci,\n",
    "                                model.decoder,\n",
    "                                ext_clf,\n",
    "                                bounds=[\n",
    "                                    (min(mins[0,i],-4.0), max(maxs[0,i],4.0))\n",
    "                                    for i in range(mins.shape[1])\n",
    "                                ],\n",
    "                                )\n",
    "    bayopts[ci].run_optimization(max_iter=BAYESIAN_OPTIMISATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ci, c in enumerate(class_names):\n",
    "    if SAVE_IMAGES:\n",
    "        # Why do they show the image inside the function???\n",
    "        for fmt in IMAGE_FORMATS:\n",
    "            bayopts[ci].plot_acquisition(filename=osp.join(images_folder,fmt,f\"{model_name}-bayes-acquisition-{ci}.{fmt}\"))\n",
    "            plt.close()\n",
    "    if SHOW_ACQUISITIONS:\n",
    "        print(c)\n",
    "        bayopts[ci].plot_acquisition()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(class_names)\n",
    "fig, axes = plt.subplots(number_of_classes, NUMBER_OF_SAMPLES_PER_CLASS)\n",
    "fig.suptitle(f\"{model_name} Random samples from the Bayesian Optimisation\")\n",
    "for ci, c in enumerate(class_names):\n",
    "    top_idx = np.argsort(bayopts[ci].Y, axis=0).ravel()\n",
    "    z_np = bayopts[ci].X[top_idx].astype(np.float32)\n",
    "    z = torch.tensor(z_np)\n",
    "    if torch.cuda.is_available(): z = z.cuda()\n",
    "    x_hat = model.decoder(z).detach().cpu().numpy()\n",
    "    x_hat = x_hat.reshape([x_hat.shape[0],*x_hat.shape[2:],x_hat.shape[1]])\n",
    "    axes[ci,0].set_ylabel(c, size=YLABEL_FONTSIZE)\n",
    "    for pi in range(NUMBER_OF_SAMPLES_PER_CLASS):\n",
    "        ax:plt.Axes = axes[ci,pi]\n",
    "        ax.imshow(x_hat[pi], vmin=0, vmax=1, cmap=\"gray\")\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.text(2.1, 0.5, \", \".join(map(\"{:.2f}\".format,z_np[pi])),\n",
    "            size=COORDS_FONTSIZE, ha='center', va='center', transform=ax.transAxes)\n",
    "if SAVE_IMAGES:\n",
    "    for fmt in IMAGE_FORMATS:\n",
    "        plt.savefig(osp.join(images_folder,fmt,f\"{model_name}-samples-bayesian-extclf.{fmt}\"))\n",
    "if SHOW_IMAGES:\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cond_vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
